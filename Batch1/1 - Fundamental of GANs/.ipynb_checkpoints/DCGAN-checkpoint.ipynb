{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UvYDZmH_xHPG"
   },
   "source": [
    "# Generative Adversarial Networks\n",
    "This code is based on https://arxiv.org/abs/1406.2661 paper from Ian J. Goodfellow, Jean Pouget-Abadie, et all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iMD0JWn1xHPJ"
   },
   "source": [
    "![title](https://github.com/muchlisinadi/DSC_UI_GAN/blob/master/batch1/week1/minmax.png?raw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 908,
     "status": "ok",
     "timestamp": 1572647284291,
     "user": {
      "displayName": "Muchlisin Adi Saputra 1306365266",
      "photoUrl": "",
      "userId": "17835414831372489696"
     },
     "user_tz": -420
    },
    "id": "mwd_26tC8NRc",
    "outputId": "8383f033-2374-4423-cbe8-fc33b3845866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ShCO79wAxHPP"
   },
   "outputs": [],
   "source": [
    "# import All prerequisites\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ROOT = \"/content/drive/My Drive/Colab Notebooks/DSC_UI_GAN/Batch1/W1/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cu6vT-jDxHPT"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gU5JFzeGxHPU"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# MNIST Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2014,
     "status": "ok",
     "timestamp": 1572647285437,
     "user": {
      "displayName": "Muchlisin Adi Saputra 1306365266",
      "photoUrl": "",
      "userId": "17835414831372489696"
     },
     "user_tz": -420
    },
    "id": "Vn1wgnIkxHPX",
    "outputId": "eed50711-1a19-419d-ce5b-f8d0dc323ac6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAELCAYAAAD+9XA2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAiCggIACIKCAgAI4v8DgVx8O5HBAtIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAELCAYAAAD+9XA2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAiCggIACIKCAgAI4v8DgVx8O5HBAtIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Print example\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wLypGXB6xHPb"
   },
   "source": [
    "## Build Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UJ_q5BflxHPc"
   },
   "source": [
    "![title](https://miro.medium.com/max/1600/1*M_YipQF_oC6owsU1VVrfhg.jpeg)\n",
    "resource : https://medium.com/@jonathan_hui/gan-whats-generative-adversarial-networks-and-its-application-f39ed278ef09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100, img_dim=(1, 28, 28)):\n",
    "        super(NormalGenerator, self).__init__()\n",
    "        img_size = img_dim[1]\n",
    "        img_channels = img_dim[0]\n",
    "\n",
    "        self.img_dim = img_dim\n",
    "        self.init_size = img_size // 4\n",
    "        self.z_dim = z_dim\n",
    "        self.linear_model = nn.Sequential(\n",
    "            nn.Linear(self.z_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_model = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, img_channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z_input):\n",
    "        out_ = self.linear_model(z_input)\n",
    "        out_ = out_.view(out_.shape[0], 128, self.init_size, self.init_size)\n",
    "        x = self.conv_model(out_)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim=(1, 28, 28)):\n",
    "        super(NormalDiscriminator, self).__init__()\n",
    "        img_size = img_dim[1]\n",
    "        img_channels = img_dim[0]\n",
    "\n",
    "        self.img_dim = img_dim\n",
    "\n",
    "        def conv_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(\n",
    "                0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.conv_model = nn.Sequential(\n",
    "            *conv_block(img_channels, 16, bn=False),\n",
    "            *conv_block(16, 32),\n",
    "            *conv_block(32, 64),\n",
    "            *conv_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = 2  # img_size // 2 ** 4\n",
    "        self.linear_model = nn.Sequential(\n",
    "            nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, img_input):\n",
    "        x = self.conv_model(img_input)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.linear_model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4316,
     "status": "ok",
     "timestamp": 1572647287772,
     "user": {
      "displayName": "Muchlisin Adi Saputra 1306365266",
      "photoUrl": "",
      "userId": "17835414831372489696"
     },
     "user_tz": -420
    },
    "id": "jNo6QGSAxHPg",
    "outputId": "3e926661-bc38-47fb-e5f7-9dbfa41fc825"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "# build network\n",
    "z_dim = 100\n",
    "mnist_dim = train_dataset.train_data.size(1) * train_dataset.train_data.size(2)\n",
    "\n",
    "G = Generator(z_dim=z_dim, img_dim=(1, 28, 28)).to(device)\n",
    "D = Discriminator(img_dim=(1, 28, 28)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4304,
     "status": "ok",
     "timestamp": 1572647287774,
     "user": {
      "displayName": "Muchlisin Adi Saputra 1306365266",
      "photoUrl": "",
      "userId": "17835414831372489696"
     },
     "user_tz": -420
    },
    "id": "zyDlKGOqxHPj",
    "outputId": "8dd5b5c2-365a-4714-8f2e-a778ffdfc0a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=128, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (3): BatchNorm1d(256, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (6): BatchNorm1d(512, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (9): BatchNorm1d(1024, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Linear(in_features=1024, out_features=784, bias=True)\n",
      "    (12): Tanh()\n",
      "  )\n",
      ") Discriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(G, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pw6SuIw-xHPm"
   },
   "source": [
    "# Train Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0jzHUZ7xHPn"
   },
   "outputs": [],
   "source": [
    "# loss\n",
    "criterion = nn.BCELoss() \n",
    "\n",
    "# optimizer\n",
    "lr = 0.0002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "G_optimizer = torch.optim.Adam(G.parameters(), lr=lr, betas=(b1, b2))\n",
    "D_optimizer = torch.optim.Adam(D.parameters(), lr=lr, betas=(b1, b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kAH0rt4zxHPq"
   },
   "source": [
    "### Why Binary Cross Entropy ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CUXei7RixHPr"
   },
   "source": [
    "![title](https://github.com/muchlisinadi/DSC_UI_GAN/blob/master/batch1/week1/BCELoss.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dq0ckidKxHPs"
   },
   "source": [
    "### Discriminator Update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZRXPjUQ8xHPu"
   },
   "source": [
    "![title](https://miro.medium.com/max/1720/1*4xAHMaUGXeOQnNJhzjq-4Q.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1k9X4YhGxHPz"
   },
   "source": [
    "### Generator Update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uLDNX_vKxHP0"
   },
   "source": [
    "### Before : <br>\n",
    "![title](https://miro.medium.com/max/1224/1*n235XEigXKL3ktL08d-CZA.jpeg) <br>\n",
    "### Because Generator diminished gradient: <br>\n",
    "In practice, equation 1 may not provide sufficient gradient for G to learn well.  Early in learning, when G is poor,D can reject samples with high confidence because they are clearly different fromthe training data.  In this case, log(1−D(G(z))) saturates.  Rather than training G to minimize log(1−D(G(z))) we can train G to maximize logD(G(z)). This objective function results in thesame fixed point of the dynamics of G and D but provides much stronger gradients early in learning. (GAN Paper)<br>\n",
    "\n",
    "![title](https://miro.medium.com/max/1517/1*6So6q3dWurG8qrmwk1y3jw.jpeg) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 64298,
     "status": "error",
     "timestamp": 1572646592735,
     "user": {
      "displayName": "Muchlisin Adi Saputra 1306365266",
      "photoUrl": "",
      "userId": "17835414831372489696"
     },
     "user_tz": -420
    },
    "id": "NX2eNdar64Xs",
    "outputId": "2f8fbc72-9810-47e4-d071-0b66d98a4729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/600] [D loss: 0.672629] [G loss: 0.718289]\n",
      "[Epoch 0/200] [Batch 300/600] [D loss: 0.525954] [G loss: 1.035763]\n",
      "[Epoch 1/200] [Batch 0/600] [D loss: 0.487692] [G loss: 0.853348]\n",
      "[Epoch 1/200] [Batch 300/600] [D loss: 0.362092] [G loss: 0.910943]\n",
      "[Epoch 2/200] [Batch 0/600] [D loss: 0.317175] [G loss: 1.666999]\n",
      "[Epoch 2/200] [Batch 300/600] [D loss: 0.340499] [G loss: 1.058032]\n",
      "[Epoch 3/200] [Batch 0/600] [D loss: 0.320626] [G loss: 1.648210]\n",
      "[Epoch 3/200] [Batch 300/600] [D loss: 0.273704] [G loss: 1.251731]\n",
      "[Epoch 4/200] [Batch 0/600] [D loss: 0.314576] [G loss: 1.135395]\n",
      "[Epoch 4/200] [Batch 300/600] [D loss: 0.557768] [G loss: 0.554418]\n",
      "[Epoch 5/200] [Batch 0/600] [D loss: 0.212887] [G loss: 1.849806]\n",
      "[Epoch 5/200] [Batch 300/600] [D loss: 0.345930] [G loss: 1.052477]\n",
      "[Epoch 6/200] [Batch 0/600] [D loss: 0.512333] [G loss: 3.889980]\n",
      "[Epoch 6/200] [Batch 300/600] [D loss: 0.225671] [G loss: 1.580570]\n",
      "[Epoch 7/200] [Batch 0/600] [D loss: 0.351296] [G loss: 2.876074]\n",
      "[Epoch 7/200] [Batch 300/600] [D loss: 0.215525] [G loss: 2.720519]\n",
      "[Epoch 8/200] [Batch 0/600] [D loss: 0.164517] [G loss: 2.734270]\n",
      "[Epoch 8/200] [Batch 300/600] [D loss: 0.263598] [G loss: 1.266533]\n",
      "[Epoch 9/200] [Batch 0/600] [D loss: 0.267152] [G loss: 2.833316]\n",
      "[Epoch 9/200] [Batch 300/600] [D loss: 0.339379] [G loss: 1.756152]\n",
      "[Epoch 10/200] [Batch 0/600] [D loss: 0.294904] [G loss: 3.498767]\n",
      "[Epoch 10/200] [Batch 300/600] [D loss: 0.181946] [G loss: 2.368709]\n",
      "[Epoch 11/200] [Batch 0/600] [D loss: 0.203361] [G loss: 1.442133]\n",
      "[Epoch 11/200] [Batch 300/600] [D loss: 0.200330] [G loss: 1.462164]\n",
      "[Epoch 12/200] [Batch 0/600] [D loss: 0.184884] [G loss: 2.402766]\n",
      "[Epoch 12/200] [Batch 300/600] [D loss: 0.132845] [G loss: 1.855809]\n",
      "[Epoch 13/200] [Batch 0/600] [D loss: 0.380838] [G loss: 0.934783]\n",
      "[Epoch 13/200] [Batch 300/600] [D loss: 0.140941] [G loss: 2.753262]\n",
      "[Epoch 14/200] [Batch 0/600] [D loss: 0.197437] [G loss: 2.221492]\n",
      "[Epoch 14/200] [Batch 300/600] [D loss: 0.068012] [G loss: 3.278993]\n",
      "[Epoch 15/200] [Batch 0/600] [D loss: 0.185778] [G loss: 2.110098]\n",
      "[Epoch 15/200] [Batch 300/600] [D loss: 0.092919] [G loss: 2.983985]\n",
      "[Epoch 16/200] [Batch 0/600] [D loss: 0.182962] [G loss: 1.965892]\n",
      "[Epoch 16/200] [Batch 300/600] [D loss: 0.184681] [G loss: 2.426325]\n",
      "[Epoch 17/200] [Batch 0/600] [D loss: 0.074307] [G loss: 3.634369]\n",
      "[Epoch 17/200] [Batch 300/600] [D loss: 0.233575] [G loss: 3.387808]\n",
      "[Epoch 18/200] [Batch 0/600] [D loss: 0.260172] [G loss: 1.661705]\n",
      "[Epoch 18/200] [Batch 300/600] [D loss: 0.229294] [G loss: 1.886500]\n",
      "[Epoch 19/200] [Batch 0/600] [D loss: 0.203859] [G loss: 3.242213]\n",
      "[Epoch 19/200] [Batch 300/600] [D loss: 0.305656] [G loss: 1.160868]\n",
      "[Epoch 20/200] [Batch 0/600] [D loss: 0.125028] [G loss: 5.638501]\n",
      "[Epoch 20/200] [Batch 300/600] [D loss: 0.123734] [G loss: 2.704532]\n",
      "[Epoch 21/200] [Batch 0/600] [D loss: 0.135739] [G loss: 3.271777]\n",
      "[Epoch 21/200] [Batch 300/600] [D loss: 0.109780] [G loss: 3.207101]\n",
      "[Epoch 22/200] [Batch 0/600] [D loss: 0.173986] [G loss: 2.098422]\n",
      "[Epoch 22/200] [Batch 300/600] [D loss: 0.207707] [G loss: 1.448907]\n",
      "[Epoch 23/200] [Batch 0/600] [D loss: 0.205523] [G loss: 3.646933]\n",
      "[Epoch 23/200] [Batch 300/600] [D loss: 0.150042] [G loss: 2.480058]\n",
      "[Epoch 24/200] [Batch 0/600] [D loss: 0.306807] [G loss: 1.007659]\n",
      "[Epoch 24/200] [Batch 300/600] [D loss: 0.196469] [G loss: 1.948711]\n",
      "[Epoch 25/200] [Batch 0/600] [D loss: 0.108304] [G loss: 3.395142]\n",
      "[Epoch 25/200] [Batch 300/600] [D loss: 0.160990] [G loss: 2.982061]\n",
      "[Epoch 26/200] [Batch 0/600] [D loss: 0.161128] [G loss: 3.701444]\n",
      "[Epoch 26/200] [Batch 300/600] [D loss: 0.349564] [G loss: 1.840867]\n",
      "[Epoch 27/200] [Batch 0/600] [D loss: 0.084747] [G loss: 3.108246]\n",
      "[Epoch 27/200] [Batch 300/600] [D loss: 0.166672] [G loss: 2.335755]\n",
      "[Epoch 28/200] [Batch 0/600] [D loss: 0.224250] [G loss: 1.360311]\n",
      "[Epoch 28/200] [Batch 300/600] [D loss: 0.191991] [G loss: 2.543197]\n",
      "[Epoch 29/200] [Batch 0/600] [D loss: 0.168914] [G loss: 2.488811]\n",
      "[Epoch 29/200] [Batch 300/600] [D loss: 0.272809] [G loss: 3.161167]\n",
      "[Epoch 30/200] [Batch 0/600] [D loss: 0.115381] [G loss: 3.282074]\n",
      "[Epoch 30/200] [Batch 300/600] [D loss: 0.115497] [G loss: 2.487820]\n",
      "[Epoch 31/200] [Batch 0/600] [D loss: 0.191542] [G loss: 1.835630]\n",
      "[Epoch 31/200] [Batch 300/600] [D loss: 0.163754] [G loss: 2.208431]\n",
      "[Epoch 32/200] [Batch 0/600] [D loss: 0.200686] [G loss: 4.760751]\n",
      "[Epoch 32/200] [Batch 300/600] [D loss: 0.133760] [G loss: 2.265532]\n",
      "[Epoch 33/200] [Batch 0/600] [D loss: 0.103521] [G loss: 2.681802]\n",
      "[Epoch 33/200] [Batch 300/600] [D loss: 0.155918] [G loss: 4.379477]\n",
      "[Epoch 34/200] [Batch 0/600] [D loss: 0.123814] [G loss: 6.607515]\n",
      "[Epoch 34/200] [Batch 300/600] [D loss: 0.166421] [G loss: 3.192551]\n",
      "[Epoch 35/200] [Batch 0/600] [D loss: 0.188987] [G loss: 2.568639]\n",
      "[Epoch 35/200] [Batch 300/600] [D loss: 0.145879] [G loss: 2.559463]\n",
      "[Epoch 36/200] [Batch 0/600] [D loss: 0.115826] [G loss: 4.009007]\n",
      "[Epoch 36/200] [Batch 300/600] [D loss: 0.128769] [G loss: 2.941931]\n",
      "[Epoch 37/200] [Batch 0/600] [D loss: 0.115107] [G loss: 2.804768]\n",
      "[Epoch 37/200] [Batch 300/600] [D loss: 0.151703] [G loss: 2.575033]\n",
      "[Epoch 38/200] [Batch 0/600] [D loss: 0.152355] [G loss: 2.842324]\n",
      "[Epoch 38/200] [Batch 300/600] [D loss: 0.100378] [G loss: 4.429636]\n",
      "[Epoch 39/200] [Batch 0/600] [D loss: 0.212899] [G loss: 1.638516]\n",
      "[Epoch 39/200] [Batch 300/600] [D loss: 0.077984] [G loss: 5.179465]\n",
      "[Epoch 40/200] [Batch 0/600] [D loss: 0.102422] [G loss: 2.464819]\n",
      "[Epoch 40/200] [Batch 300/600] [D loss: 0.148745] [G loss: 2.175438]\n",
      "[Epoch 41/200] [Batch 0/600] [D loss: 0.061319] [G loss: 2.935631]\n",
      "[Epoch 41/200] [Batch 300/600] [D loss: 0.105168] [G loss: 3.970762]\n",
      "[Epoch 42/200] [Batch 0/600] [D loss: 0.295739] [G loss: 2.282284]\n",
      "[Epoch 42/200] [Batch 300/600] [D loss: 0.216406] [G loss: 4.411835]\n",
      "[Epoch 43/200] [Batch 0/600] [D loss: 0.176601] [G loss: 2.431715]\n",
      "[Epoch 43/200] [Batch 300/600] [D loss: 0.419673] [G loss: 6.183638]\n",
      "[Epoch 44/200] [Batch 0/600] [D loss: 0.222847] [G loss: 2.792053]\n",
      "[Epoch 44/200] [Batch 300/600] [D loss: 0.194234] [G loss: 2.985660]\n",
      "[Epoch 45/200] [Batch 0/600] [D loss: 0.148568] [G loss: 2.832594]\n",
      "[Epoch 45/200] [Batch 300/600] [D loss: 0.132820] [G loss: 3.047990]\n",
      "[Epoch 46/200] [Batch 0/600] [D loss: 0.278573] [G loss: 6.457705]\n",
      "[Epoch 46/200] [Batch 300/600] [D loss: 0.183759] [G loss: 2.200760]\n",
      "[Epoch 47/200] [Batch 0/600] [D loss: 0.167566] [G loss: 2.855206]\n",
      "[Epoch 47/200] [Batch 300/600] [D loss: 0.153285] [G loss: 4.195418]\n",
      "[Epoch 48/200] [Batch 0/600] [D loss: 0.083523] [G loss: 2.719372]\n",
      "[Epoch 48/200] [Batch 300/600] [D loss: 0.193431] [G loss: 2.571358]\n",
      "[Epoch 49/200] [Batch 0/600] [D loss: 0.088921] [G loss: 3.845442]\n",
      "[Epoch 49/200] [Batch 300/600] [D loss: 0.113618] [G loss: 3.255934]\n",
      "[Epoch 50/200] [Batch 0/600] [D loss: 0.168794] [G loss: 3.022938]\n",
      "[Epoch 50/200] [Batch 300/600] [D loss: 0.106482] [G loss: 3.308064]\n",
      "[Epoch 51/200] [Batch 0/600] [D loss: 0.042528] [G loss: 4.382036]\n",
      "[Epoch 51/200] [Batch 300/600] [D loss: 0.121364] [G loss: 2.479928]\n",
      "[Epoch 52/200] [Batch 0/600] [D loss: 0.187891] [G loss: 3.122872]\n",
      "[Epoch 52/200] [Batch 300/600] [D loss: 0.152947] [G loss: 1.913126]\n",
      "[Epoch 53/200] [Batch 0/600] [D loss: 0.147546] [G loss: 3.626502]\n",
      "[Epoch 53/200] [Batch 300/600] [D loss: 0.172077] [G loss: 3.585800]\n",
      "[Epoch 54/200] [Batch 0/600] [D loss: 0.182181] [G loss: 3.159274]\n",
      "[Epoch 54/200] [Batch 300/600] [D loss: 0.145491] [G loss: 1.693040]\n",
      "[Epoch 55/200] [Batch 0/600] [D loss: 0.495974] [G loss: 7.135283]\n",
      "[Epoch 55/200] [Batch 300/600] [D loss: 0.116613] [G loss: 4.136540]\n",
      "[Epoch 56/200] [Batch 0/600] [D loss: 0.147111] [G loss: 3.452556]\n",
      "[Epoch 56/200] [Batch 300/600] [D loss: 0.097360] [G loss: 3.732553]\n",
      "[Epoch 57/200] [Batch 0/600] [D loss: 0.080659] [G loss: 3.569792]\n",
      "[Epoch 57/200] [Batch 300/600] [D loss: 0.174117] [G loss: 1.849795]\n",
      "[Epoch 58/200] [Batch 0/600] [D loss: 0.169671] [G loss: 2.362820]\n",
      "[Epoch 58/200] [Batch 300/600] [D loss: 0.232326] [G loss: 1.852676]\n",
      "[Epoch 59/200] [Batch 0/600] [D loss: 0.137092] [G loss: 2.384515]\n",
      "[Epoch 59/200] [Batch 300/600] [D loss: 0.158432] [G loss: 2.711631]\n",
      "[Epoch 60/200] [Batch 0/600] [D loss: 0.229354] [G loss: 1.870538]\n",
      "[Epoch 60/200] [Batch 300/600] [D loss: 0.148180] [G loss: 2.089880]\n",
      "[Epoch 61/200] [Batch 0/600] [D loss: 0.186056] [G loss: 4.353440]\n",
      "[Epoch 61/200] [Batch 300/600] [D loss: 0.282902] [G loss: 7.662325]\n",
      "[Epoch 62/200] [Batch 0/600] [D loss: 0.102835] [G loss: 4.429796]\n",
      "[Epoch 62/200] [Batch 300/600] [D loss: 0.092959] [G loss: 2.425856]\n",
      "[Epoch 63/200] [Batch 0/600] [D loss: 0.081112] [G loss: 3.740392]\n",
      "[Epoch 63/200] [Batch 300/600] [D loss: 0.128486] [G loss: 2.793381]\n",
      "[Epoch 64/200] [Batch 0/600] [D loss: 0.134669] [G loss: 2.243714]\n",
      "[Epoch 64/200] [Batch 300/600] [D loss: 0.200884] [G loss: 2.512537]\n",
      "[Epoch 65/200] [Batch 0/600] [D loss: 0.156475] [G loss: 3.293481]\n",
      "[Epoch 65/200] [Batch 300/600] [D loss: 0.156260] [G loss: 5.238761]\n",
      "[Epoch 66/200] [Batch 0/600] [D loss: 0.144765] [G loss: 4.508188]\n",
      "[Epoch 66/200] [Batch 300/600] [D loss: 0.166192] [G loss: 4.101498]\n",
      "[Epoch 67/200] [Batch 0/600] [D loss: 0.164232] [G loss: 3.922636]\n",
      "[Epoch 67/200] [Batch 300/600] [D loss: 0.362272] [G loss: 1.662844]\n",
      "[Epoch 68/200] [Batch 0/600] [D loss: 0.164080] [G loss: 1.924675]\n",
      "[Epoch 68/200] [Batch 300/600] [D loss: 0.100199] [G loss: 2.692280]\n",
      "[Epoch 69/200] [Batch 0/600] [D loss: 0.251654] [G loss: 1.620381]\n",
      "[Epoch 69/200] [Batch 300/600] [D loss: 0.346078] [G loss: 7.009434]\n",
      "[Epoch 70/200] [Batch 0/600] [D loss: 0.214003] [G loss: 3.578233]\n",
      "[Epoch 70/200] [Batch 300/600] [D loss: 0.084591] [G loss: 2.962661]\n",
      "[Epoch 71/200] [Batch 0/600] [D loss: 0.142839] [G loss: 4.360670]\n",
      "[Epoch 71/200] [Batch 300/600] [D loss: 0.122143] [G loss: 2.416596]\n",
      "[Epoch 72/200] [Batch 0/600] [D loss: 0.084197] [G loss: 4.440333]\n",
      "[Epoch 72/200] [Batch 300/600] [D loss: 0.112612] [G loss: 2.736804]\n",
      "[Epoch 73/200] [Batch 0/600] [D loss: 0.144879] [G loss: 3.874706]\n",
      "[Epoch 73/200] [Batch 300/600] [D loss: 0.171228] [G loss: 2.186162]\n",
      "[Epoch 74/200] [Batch 0/600] [D loss: 0.245350] [G loss: 3.309742]\n",
      "[Epoch 74/200] [Batch 300/600] [D loss: 0.205183] [G loss: 3.764778]\n",
      "[Epoch 75/200] [Batch 0/600] [D loss: 0.143321] [G loss: 2.544532]\n",
      "[Epoch 75/200] [Batch 300/600] [D loss: 0.141242] [G loss: 2.114534]\n",
      "[Epoch 76/200] [Batch 0/600] [D loss: 0.187719] [G loss: 4.064357]\n",
      "[Epoch 76/200] [Batch 300/600] [D loss: 0.164225] [G loss: 2.203065]\n",
      "[Epoch 77/200] [Batch 0/600] [D loss: 0.256802] [G loss: 2.823810]\n",
      "[Epoch 77/200] [Batch 300/600] [D loss: 0.149942] [G loss: 2.190369]\n",
      "[Epoch 78/200] [Batch 0/600] [D loss: 0.167824] [G loss: 2.411045]\n",
      "[Epoch 78/200] [Batch 300/600] [D loss: 0.141087] [G loss: 2.230250]\n",
      "[Epoch 79/200] [Batch 0/600] [D loss: 0.167265] [G loss: 3.127171]\n",
      "[Epoch 79/200] [Batch 300/600] [D loss: 0.166337] [G loss: 3.076431]\n",
      "[Epoch 80/200] [Batch 0/600] [D loss: 0.264846] [G loss: 1.436367]\n",
      "[Epoch 80/200] [Batch 300/600] [D loss: 0.142203] [G loss: 4.337371]\n",
      "[Epoch 81/200] [Batch 0/600] [D loss: 0.142224] [G loss: 2.536630]\n",
      "[Epoch 81/200] [Batch 300/600] [D loss: 0.156724] [G loss: 3.612599]\n",
      "[Epoch 82/200] [Batch 0/600] [D loss: 0.284532] [G loss: 1.825960]\n",
      "[Epoch 82/200] [Batch 300/600] [D loss: 0.174834] [G loss: 2.130871]\n",
      "[Epoch 83/200] [Batch 0/600] [D loss: 0.090731] [G loss: 3.270148]\n",
      "[Epoch 83/200] [Batch 300/600] [D loss: 0.146451] [G loss: 2.737815]\n",
      "[Epoch 84/200] [Batch 0/600] [D loss: 0.221208] [G loss: 4.672517]\n",
      "[Epoch 84/200] [Batch 300/600] [D loss: 0.119784] [G loss: 3.401246]\n",
      "[Epoch 85/200] [Batch 0/600] [D loss: 0.191432] [G loss: 1.647913]\n",
      "[Epoch 85/200] [Batch 300/600] [D loss: 0.098194] [G loss: 3.398962]\n",
      "[Epoch 86/200] [Batch 0/600] [D loss: 0.197046] [G loss: 2.239567]\n",
      "[Epoch 86/200] [Batch 300/600] [D loss: 0.202937] [G loss: 2.333792]\n",
      "[Epoch 87/200] [Batch 0/600] [D loss: 0.298044] [G loss: 1.363166]\n",
      "[Epoch 87/200] [Batch 300/600] [D loss: 0.120518] [G loss: 2.553301]\n",
      "[Epoch 88/200] [Batch 0/600] [D loss: 0.145601] [G loss: 3.460134]\n",
      "[Epoch 88/200] [Batch 300/600] [D loss: 0.149975] [G loss: 2.775134]\n",
      "[Epoch 89/200] [Batch 0/600] [D loss: 0.237267] [G loss: 1.785302]\n",
      "[Epoch 89/200] [Batch 300/600] [D loss: 0.102703] [G loss: 2.960909]\n",
      "[Epoch 90/200] [Batch 0/600] [D loss: 0.218154] [G loss: 2.453160]\n",
      "[Epoch 90/200] [Batch 300/600] [D loss: 0.231946] [G loss: 3.156985]\n",
      "[Epoch 91/200] [Batch 0/600] [D loss: 0.142099] [G loss: 2.559675]\n",
      "[Epoch 91/200] [Batch 300/600] [D loss: 0.155160] [G loss: 2.317512]\n",
      "[Epoch 92/200] [Batch 0/600] [D loss: 0.128616] [G loss: 2.742586]\n",
      "[Epoch 92/200] [Batch 300/600] [D loss: 0.112119] [G loss: 2.950532]\n",
      "[Epoch 93/200] [Batch 0/600] [D loss: 0.286999] [G loss: 6.247541]\n",
      "[Epoch 93/200] [Batch 300/600] [D loss: 0.145135] [G loss: 3.176577]\n",
      "[Epoch 94/200] [Batch 0/600] [D loss: 0.159155] [G loss: 3.088279]\n",
      "[Epoch 94/200] [Batch 300/600] [D loss: 0.133448] [G loss: 2.926852]\n",
      "[Epoch 95/200] [Batch 0/600] [D loss: 0.238213] [G loss: 5.665673]\n",
      "[Epoch 95/200] [Batch 300/600] [D loss: 0.160749] [G loss: 3.585735]\n",
      "[Epoch 96/200] [Batch 0/600] [D loss: 0.159915] [G loss: 2.012029]\n",
      "[Epoch 96/200] [Batch 300/600] [D loss: 0.152434] [G loss: 2.621027]\n",
      "[Epoch 97/200] [Batch 0/600] [D loss: 0.319654] [G loss: 2.498996]\n",
      "[Epoch 97/200] [Batch 300/600] [D loss: 0.183211] [G loss: 2.185059]\n",
      "[Epoch 98/200] [Batch 0/600] [D loss: 0.456066] [G loss: 1.078002]\n",
      "[Epoch 98/200] [Batch 300/600] [D loss: 0.193235] [G loss: 3.349806]\n"
     ]
    }
   ],
   "source": [
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs, _) in enumerate(train_loader):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        G_optimizer.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], z_dim))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = G(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = criterion(D(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        D_optimizer.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = criterion(D(real_imgs), valid)\n",
    "        fake_loss = criterion(D(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        D_optimizer.step()\n",
    "        if i % 300 == 0:\n",
    "            print(\n",
    "              \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "              % (epoch, epochs, i, len(train_loader), d_loss.item(), g_loss.item()))\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        save_image(gen_imgs.view(gen_imgs.size(0), 1, 28, 28), ROOT + \"sample/%d.png\" % epoch, nrow=5, normalize=True)\n",
    "\n",
    "torch.save(G, ROOT + 'G.pt')\n",
    "torch.save(D, ROOT + 'D.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of W1 .ipynb",
   "provenance": [
    {
     "file_id": "1eweqg9Qaci_mo5rhnH7knZCqZZ7FDkLy",
     "timestamp": 1572649016096
    },
    {
     "file_id": "https://github.com/muchlisinadi/DSC_UI_GAN/blob/master/batch1/week1/W1.ipynb",
     "timestamp": 1572627799240
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
